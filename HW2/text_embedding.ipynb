{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "44b826af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from fastembed import TextEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0c5078f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_handle = \"jinaai/jina-embeddings-v2-small-en\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a56361b",
   "metadata": {},
   "source": [
    "### Q1) Embedding the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "33b14fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding shape: (512,)\n"
     ]
    }
   ],
   "source": [
    "q ='I just discovered the course. Can I join now?'\n",
    "\n",
    "# Initialize the DefaultEmbedding class with the desired parameters\n",
    "embedding_model = TextEmbedding(model_name=model_handle)\n",
    "# Generate the embedding for the query\n",
    "embedding = list(embedding_model.embed(q))\n",
    "embeddings = embedding[0]\n",
    "# Print the shape of the embedding\n",
    "print(f\"Embedding shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3a25a215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-0.11726373885183883)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933198f1",
   "metadata": {},
   "source": [
    "-0.11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5d78c9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of the embedding vector: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# import  \n",
    "\n",
    "norm= np.linalg.norm(embeddings)  # L2 norm of the embedding vector\n",
    "print(f\"Norm of the embedding vector: {norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "adb289d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot product of the embedding vector with itself: 1.0000000000000002\n"
     ]
    }
   ],
   "source": [
    "# dot product of the embedding vector with itself\n",
    "dot_product = np.dot(embeddings, embeddings)\n",
    "print(f\"Dot product of the embedding vector with itself: {dot_product}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a65bd39",
   "metadata": {},
   "source": [
    "### Q2) Cosine similarity with another vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cd36c5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between query and document: 0.9008528895674548\n"
     ]
    }
   ],
   "source": [
    "doc = 'Can I still join the course after the start date?'\n",
    "\n",
    "embedding_doc = list(embedding_model.embed(doc))\n",
    "embeddings_doc = embedding_doc[0]\n",
    "\n",
    "# Calculate the cosine similarity between the query and document embeddings\n",
    "cosine_similarity = np.dot(embeddings, embeddings_doc) / (np.linalg.norm(embeddings) * np.linalg.norm(embeddings_doc))\n",
    "print(f\"Cosine similarity between query and document: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319b9198",
   "metadata": {},
   "source": [
    "0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eb4ed0",
   "metadata": {},
   "source": [
    "### Q3) Cosine similarity version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6e6789ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [{'text': \"Yes, even if you don't register, you're still eligible to submit the homeworks.\\nBe aware, however, that there will be deadlines for turning in the final projects. So don't leave everything for the last minute.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I still join the course after the start date?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Yes, we will keep all the materials after the course finishes, so you can follow the course at your own pace after it finishes.\\nYou can also continue looking at the homeworks and continue preparing for the next cohort. I guess you can also start working on your final capstone project.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - Can I follow the course after it finishes?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': \"The purpose of this document is to capture frequently asked technical questions\\nThe exact day and hour of the course will be 15th Jan 2024 at 17h00. The course will start with the first  “Office Hours'' live.1\\nSubscribe to course public Google Calendar (it works from Desktop only).\\nRegister before the course starts using this link.\\nJoin the course Telegram channel with announcements.\\nDon’t forget to register in DataTalks.Club's Slack and join the channel.\",\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - When will the course start?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'You can start by installing and setting up all the dependencies and requirements:\\nGoogle cloud account\\nGoogle Cloud SDK\\nPython 3 (installed with Anaconda)\\nTerraform\\nGit\\nLook over the prerequisites and syllabus to see if you are comfortable with these subjects.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'Course - What can I do before the course starts?',\n",
    "  'course': 'data-engineering-zoomcamp'},\n",
    " {'text': 'Star the repo! Share it with friends if you find it useful ❣️\\nCreate a PR if you see you can improve the text or the structure of the repository.',\n",
    "  'section': 'General course-related questions',\n",
    "  'question': 'How can we contribute to the course?',\n",
    "  'course': 'data-engineering-zoomcamp'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "de29dbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings from text field of each document\n",
    "new_doc_embeddings = []\n",
    "for doc in documents:\n",
    "    # Generate the embedding for each document\n",
    "    embedding_doc = list(embedding_model.embed(doc['text']))\n",
    "    embeddings_doc = embedding_doc[0]\n",
    "    new_doc_embeddings.append(embeddings_doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f202a927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between query and first document: [0.76296847 0.81823782 0.80853974 0.7133079  0.73044992]\n"
     ]
    }
   ],
   "source": [
    "first_cosine_similarity = np.dot(new_doc_embeddings,embeddings) \n",
    "print(f\"Cosine similarity between query and first document: {first_cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d370e3a9",
   "metadata": {},
   "source": [
    "document index with the highest similarity: 1 @ 0.818"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "04850355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between query and first document with full text: [0.85145432 0.84365942 0.8408287  0.7755158  0.80860078]\n"
     ]
    }
   ],
   "source": [
    "new_doc_embeddings_2 = []\n",
    "for doc in documents:\n",
    "    # Generate the embedding for each document\n",
    "    full_text = doc['question'] + ' ' + doc['text']\n",
    "    embedding_doc = list(embedding_model.embed(full_text))\n",
    "    embeddings_doc = embedding_doc[0]\n",
    "    new_doc_embeddings_2.append(embeddings_doc)\n",
    "\n",
    "first_cosine_similarity_2 = np.dot(new_doc_embeddings_2, embeddings)\n",
    "print(f\"Cosine similarity between query and first document with full text: {first_cosine_similarity_2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64837835",
   "metadata": {},
   "source": [
    "Index of the doc with most match is 0 @ 0.85\n",
    "\n",
    "This is different from Q3 because the question field enriches the context and the similarity score is boosted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0515f62e",
   "metadata": {},
   "source": [
    "### Q5) Selecting the embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a5e035e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "description",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "license",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "size_in_GB",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "dim",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "tasks",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "7a709e36-eb92-4378-8b4a-11c41eb0e1cf",
       "rows": [
        [
         "0",
         "BAAI/bge-small-en",
         "Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.",
         "mit",
         "0.13",
         "384",
         "{}"
        ],
        [
         "1",
         "BAAI/bge-small-en-v1.5",
         "Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.",
         "mit",
         "0.067",
         "384",
         "{}"
        ],
        [
         "2",
         "snowflake/snowflake-arctic-embed-xs",
         "Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.",
         "apache-2.0",
         "0.09",
         "384",
         "{}"
        ],
        [
         "3",
         "snowflake/snowflake-arctic-embed-s",
         "Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.",
         "apache-2.0",
         "0.13",
         "384",
         "{}"
        ],
        [
         "4",
         "sentence-transformers/all-MiniLM-L6-v2",
         "Text embeddings, Unimodal (text), English, 256 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.",
         "apache-2.0",
         "0.09",
         "384",
         "{}"
        ],
        [
         "5",
         "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
         "Text embeddings, Unimodal (text), Multilingual (~50 languages), 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2019 year.",
         "apache-2.0",
         "0.22",
         "384",
         "{}"
        ],
        [
         "6",
         "BAAI/bge-small-zh-v1.5",
         "Text embeddings, Unimodal (text), Chinese, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.",
         "mit",
         "0.09",
         "512",
         "{}"
        ],
        [
         "7",
         "Qdrant/clip-ViT-B-32-text",
         "Text embeddings, Multimodal (text&image), English, 77 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year",
         "mit",
         "0.25",
         "512",
         "{}"
        ],
        [
         "8",
         "jinaai/jina-embeddings-v2-small-en",
         "Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.",
         "apache-2.0",
         "0.12",
         "512",
         "{}"
        ],
        [
         "9",
         "snowflake/snowflake-arctic-embed-m-long",
         "Text embeddings, Unimodal (text), English, 2048 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.",
         "apache-2.0",
         "0.54",
         "768",
         "{}"
        ],
        [
         "10",
         "jinaai/jina-clip-v1",
         "Text embeddings, Multimodal (text&image), English, Prefixes for queries/documents: not necessary, 2024 year",
         "apache-2.0",
         "0.55",
         "768",
         "{}"
        ],
        [
         "11",
         "snowflake/snowflake-arctic-embed-m",
         "Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.",
         "apache-2.0",
         "0.43",
         "768",
         "{}"
        ],
        [
         "12",
         "jinaai/jina-embeddings-v2-base-en",
         "Text embeddings, Unimodal (text), English, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.",
         "apache-2.0",
         "0.52",
         "768",
         "{}"
        ],
        [
         "13",
         "jinaai/jina-embeddings-v2-base-code",
         "Text embeddings, Unimodal (text), Multilingual (English, 30 programming languages), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.",
         "apache-2.0",
         "0.64",
         "768",
         "{}"
        ],
        [
         "14",
         "BAAI/bge-base-en-v1.5",
         "Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.",
         "mit",
         "0.21",
         "768",
         "{}"
        ],
        [
         "15",
         "BAAI/bge-base-en",
         "Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2023 year.",
         "mit",
         "0.42",
         "768",
         "{}"
        ],
        [
         "16",
         "nomic-ai/nomic-embed-text-v1",
         "Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.",
         "apache-2.0",
         "0.52",
         "768",
         "{}"
        ],
        [
         "17",
         "nomic-ai/nomic-embed-text-v1.5-Q",
         "Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.",
         "apache-2.0",
         "0.13",
         "768",
         "{}"
        ],
        [
         "18",
         "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
         "Text embeddings, Unimodal (text), Multilingual (~50 languages), 384 input tokens truncation, Prefixes for queries/documents: not necessary, 2021 year.",
         "apache-2.0",
         "1.0",
         "768",
         "{}"
        ],
        [
         "19",
         "jinaai/jina-embeddings-v2-base-de",
         "Text embeddings, Unimodal (text), Multilingual (German, English), 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.",
         "apache-2.0",
         "0.32",
         "768",
         "{}"
        ],
        [
         "20",
         "jinaai/jina-embeddings-v2-base-es",
         "Text embeddings, Unimodal (text), supports mixed Spanish-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.",
         "apache-2.0",
         "0.64",
         "768",
         "{}"
        ],
        [
         "21",
         "thenlper/gte-base",
         "General text embeddings, Unimodal (text), supports English only input text, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.",
         "mit",
         "0.44",
         "768",
         "{}"
        ],
        [
         "22",
         "nomic-ai/nomic-embed-text-v1.5",
         "Text embeddings, Multimodal (text, image), English, 8192 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.",
         "apache-2.0",
         "0.52",
         "768",
         "{}"
        ],
        [
         "23",
         "jinaai/jina-embeddings-v2-base-zh",
         "Text embeddings, Unimodal (text), supports mixed Chinese-English input text, 8192 input tokens truncation, Prefixes for queries/documents: not necessary, 2024 year.",
         "apache-2.0",
         "0.64",
         "768",
         "{}"
        ],
        [
         "24",
         "snowflake/snowflake-arctic-embed-l",
         "Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.",
         "apache-2.0",
         "1.02",
         "1024",
         "{}"
        ],
        [
         "25",
         "mixedbread-ai/mxbai-embed-large-v1",
         "Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.",
         "apache-2.0",
         "0.64",
         "1024",
         "{}"
        ],
        [
         "26",
         "BAAI/bge-large-en-v1.5",
         "Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not so necessary, 2023 year.",
         "mit",
         "1.2",
         "1024",
         "{}"
        ],
        [
         "27",
         "thenlper/gte-large",
         "Text embeddings, Unimodal (text), English, 512 input tokens truncation, Prefixes for queries/documents: not necessary, 2023 year.",
         "mit",
         "1.2",
         "1024",
         "{}"
        ],
        [
         "28",
         "intfloat/multilingual-e5-large",
         "Text embeddings, Unimodal (text), Multilingual (~100 languages), 512 input tokens truncation, Prefixes for queries/documents: necessary, 2024 year.",
         "mit",
         "2.24",
         "1024",
         "{}"
        ],
        [
         "29",
         "jinaai/jina-embeddings-v3",
         "Multi-task unimodal (text) embedding model, multi-lingual (~100), 1024 tokens truncation, and 8192 sequence length. Prefixes for queries/documents: not necessary, 2024 year.",
         "cc-by-nc-4.0",
         "2.29",
         "1024",
         "{'retrieval.query': 0, 'retrieval.passage': 1, 'separation': 2, 'classification': 3, 'text-matching': 4}"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 30
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>description</th>\n",
       "      <th>license</th>\n",
       "      <th>size_in_GB</th>\n",
       "      <th>dim</th>\n",
       "      <th>tasks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BAAI/bge-small-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.130</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BAAI/bge-small-en-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.067</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-xs</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-s</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.130</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sentence-transformers/all-MiniLM-L6-v2</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 256...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.220</td>\n",
       "      <td>384</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BAAI/bge-small-zh-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), Chinese, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.090</td>\n",
       "      <td>512</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qdrant/clip-ViT-B-32-text</td>\n",
       "      <td>Text embeddings, Multimodal (text&amp;image), Engl...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.250</td>\n",
       "      <td>512</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>jinaai/jina-embeddings-v2-small-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 819...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.120</td>\n",
       "      <td>512</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-m-long</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 204...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.540</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>jinaai/jina-clip-v1</td>\n",
       "      <td>Text embeddings, Multimodal (text&amp;image), Engl...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-m</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.430</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 819...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-code</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BAAI/bge-base-en-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.210</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BAAI/bge-base-en</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.420</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1</td>\n",
       "      <td>Text embeddings, Multimodal (text, image), Eng...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1.5-Q</td>\n",
       "      <td>Text embeddings, Multimodal (text, image), Eng...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.130</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sentence-transformers/paraphrase-multilingual-...</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-de</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.320</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-es</td>\n",
       "      <td>Text embeddings, Unimodal (text), supports mix...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>thenlper/gte-base</td>\n",
       "      <td>General text embeddings, Unimodal (text), supp...</td>\n",
       "      <td>mit</td>\n",
       "      <td>0.440</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>nomic-ai/nomic-embed-text-v1.5</td>\n",
       "      <td>Text embeddings, Multimodal (text, image), Eng...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.520</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>jinaai/jina-embeddings-v2-base-zh</td>\n",
       "      <td>Text embeddings, Unimodal (text), supports mix...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>768</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>snowflake/snowflake-arctic-embed-l</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>mixedbread-ai/mxbai-embed-large-v1</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>apache-2.0</td>\n",
       "      <td>0.640</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BAAI/bge-large-en-v1.5</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>thenlper/gte-large</td>\n",
       "      <td>Text embeddings, Unimodal (text), English, 512...</td>\n",
       "      <td>mit</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>intfloat/multilingual-e5-large</td>\n",
       "      <td>Text embeddings, Unimodal (text), Multilingual...</td>\n",
       "      <td>mit</td>\n",
       "      <td>2.240</td>\n",
       "      <td>1024</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>jinaai/jina-embeddings-v3</td>\n",
       "      <td>Multi-task unimodal (text) embedding model, mu...</td>\n",
       "      <td>cc-by-nc-4.0</td>\n",
       "      <td>2.290</td>\n",
       "      <td>1024</td>\n",
       "      <td>{'retrieval.query': 0, 'retrieval.passage': 1,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                model  \\\n",
       "0                                   BAAI/bge-small-en   \n",
       "1                              BAAI/bge-small-en-v1.5   \n",
       "2                 snowflake/snowflake-arctic-embed-xs   \n",
       "3                  snowflake/snowflake-arctic-embed-s   \n",
       "4              sentence-transformers/all-MiniLM-L6-v2   \n",
       "5   sentence-transformers/paraphrase-multilingual-...   \n",
       "6                              BAAI/bge-small-zh-v1.5   \n",
       "7                           Qdrant/clip-ViT-B-32-text   \n",
       "8                  jinaai/jina-embeddings-v2-small-en   \n",
       "9             snowflake/snowflake-arctic-embed-m-long   \n",
       "10                                jinaai/jina-clip-v1   \n",
       "11                 snowflake/snowflake-arctic-embed-m   \n",
       "12                  jinaai/jina-embeddings-v2-base-en   \n",
       "13                jinaai/jina-embeddings-v2-base-code   \n",
       "14                              BAAI/bge-base-en-v1.5   \n",
       "15                                   BAAI/bge-base-en   \n",
       "16                       nomic-ai/nomic-embed-text-v1   \n",
       "17                   nomic-ai/nomic-embed-text-v1.5-Q   \n",
       "18  sentence-transformers/paraphrase-multilingual-...   \n",
       "19                  jinaai/jina-embeddings-v2-base-de   \n",
       "20                  jinaai/jina-embeddings-v2-base-es   \n",
       "21                                  thenlper/gte-base   \n",
       "22                     nomic-ai/nomic-embed-text-v1.5   \n",
       "23                  jinaai/jina-embeddings-v2-base-zh   \n",
       "24                 snowflake/snowflake-arctic-embed-l   \n",
       "25                 mixedbread-ai/mxbai-embed-large-v1   \n",
       "26                             BAAI/bge-large-en-v1.5   \n",
       "27                                 thenlper/gte-large   \n",
       "28                     intfloat/multilingual-e5-large   \n",
       "29                          jinaai/jina-embeddings-v3   \n",
       "\n",
       "                                          description       license  \\\n",
       "0   Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "1   Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "2   Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "3   Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "4   Text embeddings, Unimodal (text), English, 256...    apache-2.0   \n",
       "5   Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "6   Text embeddings, Unimodal (text), Chinese, 512...           mit   \n",
       "7   Text embeddings, Multimodal (text&image), Engl...           mit   \n",
       "8   Text embeddings, Unimodal (text), English, 819...    apache-2.0   \n",
       "9   Text embeddings, Unimodal (text), English, 204...    apache-2.0   \n",
       "10  Text embeddings, Multimodal (text&image), Engl...    apache-2.0   \n",
       "11  Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "12  Text embeddings, Unimodal (text), English, 819...    apache-2.0   \n",
       "13  Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "14  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "15  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "16  Text embeddings, Multimodal (text, image), Eng...    apache-2.0   \n",
       "17  Text embeddings, Multimodal (text, image), Eng...    apache-2.0   \n",
       "18  Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "19  Text embeddings, Unimodal (text), Multilingual...    apache-2.0   \n",
       "20  Text embeddings, Unimodal (text), supports mix...    apache-2.0   \n",
       "21  General text embeddings, Unimodal (text), supp...           mit   \n",
       "22  Text embeddings, Multimodal (text, image), Eng...    apache-2.0   \n",
       "23  Text embeddings, Unimodal (text), supports mix...    apache-2.0   \n",
       "24  Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "25  Text embeddings, Unimodal (text), English, 512...    apache-2.0   \n",
       "26  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "27  Text embeddings, Unimodal (text), English, 512...           mit   \n",
       "28  Text embeddings, Unimodal (text), Multilingual...           mit   \n",
       "29  Multi-task unimodal (text) embedding model, mu...  cc-by-nc-4.0   \n",
       "\n",
       "    size_in_GB   dim                                              tasks  \n",
       "0        0.130   384                                                 {}  \n",
       "1        0.067   384                                                 {}  \n",
       "2        0.090   384                                                 {}  \n",
       "3        0.130   384                                                 {}  \n",
       "4        0.090   384                                                 {}  \n",
       "5        0.220   384                                                 {}  \n",
       "6        0.090   512                                                 {}  \n",
       "7        0.250   512                                                 {}  \n",
       "8        0.120   512                                                 {}  \n",
       "9        0.540   768                                                 {}  \n",
       "10       0.550   768                                                 {}  \n",
       "11       0.430   768                                                 {}  \n",
       "12       0.520   768                                                 {}  \n",
       "13       0.640   768                                                 {}  \n",
       "14       0.210   768                                                 {}  \n",
       "15       0.420   768                                                 {}  \n",
       "16       0.520   768                                                 {}  \n",
       "17       0.130   768                                                 {}  \n",
       "18       1.000   768                                                 {}  \n",
       "19       0.320   768                                                 {}  \n",
       "20       0.640   768                                                 {}  \n",
       "21       0.440   768                                                 {}  \n",
       "22       0.520   768                                                 {}  \n",
       "23       0.640   768                                                 {}  \n",
       "24       1.020  1024                                                 {}  \n",
       "25       0.640  1024                                                 {}  \n",
       "26       1.200  1024                                                 {}  \n",
       "27       1.200  1024                                                 {}  \n",
       "28       2.240  1024                                                 {}  \n",
       "29       2.290  1024  {'retrieval.query': 0, 'retrieval.passage': 1,...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "supported_models = (\n",
    "    pd.DataFrame(TextEmbedding.list_supported_models())\n",
    "    .sort_values(\"dim\", ascending=True)\n",
    "    .drop(columns=[\"sources\", \"model_file\", \"additional_files\"])\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "supported_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7b0d83",
   "metadata": {},
   "source": [
    "384 is the smallest dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "adfe86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install -q \"qdrant-client[fastembed]>=1.14.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5048495a",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnexpectedResponse",
     "evalue": "Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `zoomcamp-rag_hw` already exists!\"},\"time\":0.00042013}'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnexpectedResponse\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[86]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m collection_name = \u001b[33m\"\u001b[39m\u001b[33mzoomcamp-rag_hw\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Create the collection with specified vector parameters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mVectorParams\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEMBEDDING_DIMENSIONALITY\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Dimensionality of the vectors\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdistance\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDistance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCOSINE\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Distance metric for similarity search\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DataScience\\llmzoom2025\\llmzoom\\.venv\\Lib\\site-packages\\qdrant_client\\qdrant_client.py:2382\u001b[39m, in \u001b[36mQdrantClient.create_collection\u001b[39m\u001b[34m(self, collection_name, vectors_config, sparse_vectors_config, shard_number, sharding_method, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, timeout, strict_mode_config, **kwargs)\u001b[39m\n\u001b[32m   2332\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create empty collection with given parameters\u001b[39;00m\n\u001b[32m   2333\u001b[39m \n\u001b[32m   2334\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2378\u001b[39m \u001b[33;03m    Operation result\u001b[39;00m\n\u001b[32m   2379\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2380\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) == \u001b[32m0\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnknown arguments: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs.keys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2382\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2383\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvectors_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2385\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshard_number\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshard_number\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2386\u001b[39m \u001b[43m    \u001b[49m\u001b[43msharding_method\u001b[49m\u001b[43m=\u001b[49m\u001b[43msharding_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2387\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreplication_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreplication_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2388\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwrite_consistency_factor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwrite_consistency_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2389\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_disk_payload\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_disk_payload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2390\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhnsw_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhnsw_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2391\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizers_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizers_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2392\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwal_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwal_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2393\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2394\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_from\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_from\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2396\u001b[39m \u001b[43m    \u001b[49m\u001b[43msparse_vectors_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43msparse_vectors_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict_mode_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict_mode_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2398\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2399\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DataScience\\llmzoom2025\\llmzoom\\.venv\\Lib\\site-packages\\qdrant_client\\qdrant_remote.py:2815\u001b[39m, in \u001b[36mQdrantRemote.create_collection\u001b[39m\u001b[34m(self, collection_name, vectors_config, shard_number, replication_factor, write_consistency_factor, on_disk_payload, hnsw_config, optimizers_config, wal_config, quantization_config, init_from, timeout, sparse_vectors_config, sharding_method, strict_mode_config, **kwargs)\u001b[39m\n\u001b[32m   2797\u001b[39m     init_from = GrpcToRest.convert_init_from(init_from)\n\u001b[32m   2799\u001b[39m create_collection_request = models.CreateCollection(\n\u001b[32m   2800\u001b[39m     vectors=vectors_config,\n\u001b[32m   2801\u001b[39m     shard_number=shard_number,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2812\u001b[39m     strict_mode_config=strict_mode_config,\n\u001b[32m   2813\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m2815\u001b[39m result: Optional[\u001b[38;5;28mbool\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollections_api\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2816\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2817\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcreate_collection_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2818\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2819\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m.result\n\u001b[32m   2821\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mCreate collection returned None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2822\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DataScience\\llmzoom2025\\llmzoom\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api\\collections_api.py:294\u001b[39m, in \u001b[36mSyncCollectionsApi.create_collection\u001b[39m\u001b[34m(self, collection_name, timeout, create_collection)\u001b[39m\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate_collection\u001b[39m(\n\u001b[32m    286\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    287\u001b[39m     collection_name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    288\u001b[39m     timeout: \u001b[38;5;28mint\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    289\u001b[39m     create_collection: m.CreateCollection = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    290\u001b[39m ) -> m.InlineResponse200:\n\u001b[32m    291\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m    Create new collection with given parameters\u001b[39;00m\n\u001b[32m    293\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_build_for_create_collection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcreate_collection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DataScience\\llmzoom2025\\llmzoom\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api\\collections_api.py:96\u001b[39m, in \u001b[36m_CollectionsApi._build_for_create_collection\u001b[39m\u001b[34m(self, collection_name, timeout, create_collection)\u001b[39m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m headers:\n\u001b[32m     95\u001b[39m     headers[\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m=\u001b[49m\u001b[43mm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInlineResponse200\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPUT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/collections/\u001b[39;49m\u001b[38;5;132;43;01m{collection_name}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DataScience\\llmzoom2025\\llmzoom\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:95\u001b[39m, in \u001b[36mApiClient.request\u001b[39m\u001b[34m(self, type_, method, url, path_params, **kwargs)\u001b[39m\n\u001b[32m     93\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mint\u001b[39m(kwargs[\u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     94\u001b[39m request = \u001b[38;5;28mself\u001b[39m._client.build_request(method, url, **kwargs)\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtype_\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\DataScience\\llmzoom2025\\llmzoom\\.venv\\Lib\\site-packages\\qdrant_client\\http\\api_client.py:130\u001b[39m, in \u001b[36mApiClient.send\u001b[39m\u001b[34m(self, request, type_)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    129\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ResponseHandlingException(e)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m UnexpectedResponse.for_response(response)\n",
      "\u001b[31mUnexpectedResponse\u001b[39m: Unexpected Response: 409 (Conflict)\nRaw response content:\nb'{\"status\":{\"error\":\"Wrong input: Collection `zoomcamp-rag_hw` already exists!\"},\"time\":0.00042013}'"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient, models\n",
    "\n",
    "client = QdrantClient(\"http://localhost:6333\") #connecting to local Qdrant instance\n",
    "model_handle = \"BAAI/bge-small-en\"\n",
    "embedding_model = TextEmbedding(model_name=model_handle)\n",
    "\n",
    "EMBEDDING_DIMENSIONALITY = 384\n",
    "\n",
    "# Define the collection name\n",
    "collection_name = \"zoomcamp-rag_hw\"\n",
    "\n",
    "# Create the collection with specified vector parameters\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=EMBEDDING_DIMENSIONALITY,  # Dimensionality of the vectors\n",
    "        distance=models.Distance.COSINE  # Distance metric for similarity search\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "58239787",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "points = []\n",
    "id = 0\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "    if course_name != 'machine-learning-zoomcamp':\n",
    "        continue\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "        full_text = doc['question'] + ' ' + doc['text']\n",
    "        # print(f\"Processing document: {doc['question']}\")\n",
    "    # Create points for each document with embeddings\n",
    "        point = models.PointStruct(\n",
    "                id=id,\n",
    "                vector=models.Document(text=full_text, model=model_handle), #embed text locally with \"jinaai/jina-embeddings-v2-small-en\" from FastEmbed\n",
    "                payload={\n",
    "                    \"text\": full_text,\n",
    "                    \"section\": doc['section'],\n",
    "                    \"course\": course_name\n",
    "                } #save all needed metadata fields\n",
    "            )\n",
    "        points.append(point)\n",
    "\n",
    "        id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634c14cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UpdateResult(operation_id=0, status=<UpdateStatus.COMPLETED: 'completed'>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.upsert(\n",
    "    collection_name=collection_name,\n",
    "    points=points\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0bcff164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: I just discovered the course. Can I join now?\n",
      "Top results: The course has already started. Can I still join it? Yes, you can. You won’t be able to submit some of the homeworks, but you can still take part in the course.\n",
      "In order to get a certificate, you need to submit 2 out of 3 course projects and review 3 peers’ Projects by the deadline. It means that if you join the course at the end of November and manage to work on two projects, you will still be eligible for a certificate.\n",
      "Score for the top result: 0.8703172\n"
     ]
    }
   ],
   "source": [
    "q ='I just discovered the course. Can I join now?'\n",
    "\n",
    "def search(query, limit=1):\n",
    "\n",
    "    results = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=models.Document( #embed the query text locally with \"jinaai/jina-embeddings-v2-small-en\"\n",
    "            text=query,\n",
    "            model=model_handle \n",
    "        ),\n",
    "        limit=limit, # top closest matches\n",
    "        with_payload=True #to get metadata in the results\n",
    "    )\n",
    "\n",
    "    return results\n",
    "\n",
    "# Search for the query in the collection\n",
    "result = search(q, limit=5)\n",
    "\n",
    "print(f\"Query: {q}\")\n",
    "print(\"Top results:\", result.points[0].payload['text'])\n",
    "print(\"Score for the top result:\", result.points[0].score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01612c85",
   "metadata": {},
   "source": [
    "0.87 - Score for the top result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d62c2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
